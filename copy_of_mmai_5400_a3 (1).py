# -*- coding: utf-8 -*-
"""Copy of MMAI_5400_A3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-kXkBYdIRKSPZzSHGxIXi25tWdiLGDA
"""

import locale
locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')  # Or replace with your preferred locale

!pip3 install "setfit[absa]"
!pip3 install setfit
!python -m spacy download en_core_web_sm
!pip3 install -U setfit transformers sentence-transformers

pip install transformers==4.42.2

#!pip install --force-reinstall datasets

import os
from datetime import datetime
from datasets import load_dataset
from setfit import AbsaModel, AbsaTrainer, TrainingArguments
from transformers import EarlyStoppingCallback

# Ensure the correct version of transformers is used
import transformers
if transformers.__version__ != "4.42.2":
    raise ImportError("This script requires transformers version 4.42.2")

# Remove unnecessary imports
# from sentence_transformers import SentenceTransformer
# from transformers import AutoTokenizer
# import spacy

# Remove unnecessary initializations
# tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
# spacy.prefer_gpu()
# nlp = spacy.load("en_core_web_sm")

# Mount Google Drive and set up project directory
from google.colab import drive
drive.mount('/content/gdrive')

# Set up project directory path
pwd_path = '/content/gdrive/MyDrive/MMAI_5400_Assignment_3'

# Create directories if they don't exist
import os
os.makedirs(pwd_path, exist_ok=True)
os.makedirs(os.path.join(pwd_path, 'models'), exist_ok=True)

print(f"Project directory: {pwd_path}")
print(f"Model save path: {os.path.join(pwd_path, 'models')}")

from datasets import load_dataset

def prepare_datasets():
    """Load and prepare training and evaluation datasets."""
    dataset = load_dataset("tomaarsen/setfit-absa-semeval-restaurants")
    train_dataset = dataset["train"]
    eval_dataset = dataset["test"]
    return train_dataset, eval_dataset

def initialize_model():
    """Initialize the ABSA model."""
    model = AbsaModel.from_pretrained(
        "tomaarsen/setfit-absa-bge-small-en-v1.5-restaurants-aspect",
        "tomaarsen/setfit-absa-bge-small-en-v1.5-restaurants-polarity",
        spacy_model="en_core_web_sm"
    )
    return model

def get_training_args():
    """Configure training arguments."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"./absa_model_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)

    return TrainingArguments(
        output_dir=output_dir,
        num_epochs=5,
        batch_size=16,
        eval_steps=50,
        save_steps=50,
        load_best_model_at_end=True,
        metric_for_best_model="accuracy"
    )

from setfit import AbsaTrainer, TrainingArguments

def train_model(model, train_dataset, eval_dataset, training_args):
    """
    Train the ABSA model.

    Args:
        model: The AbsaModel to be trained.
        train_dataset: The dataset for training.
        eval_dataset: The dataset for evaluation.
        training_args: TrainingArguments for training the model.

    Returns:
        trainer: The trained model's trainer.
        metrics: Evaluation metrics on the eval_dataset.
    """
    # Initialize the trainer
    trainer = AbsaTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset
    )

    # Train the model
    try:
        trainer.train()
    except Exception as e:
        print(f"Training failed: {str(e)}")
        return None, None

    # Evaluate the model
    metrics = trainer.evaluate(eval_dataset)

    return trainer, metrics

def main():
    try:
        train_dataset, eval_dataset = prepare_datasets()
        model = initialize_model()
        training_args = get_training_args()
        trainer, metrics = train_model(model, train_dataset, eval_dataset, training_args)
        trainer.save_model("./absa_model_final_aspect", "./absa_model_final_polarity")
        print("\nTraining completed successfully!")
        print(f"Model saved to: ./absa_model_final_aspect and ./absa_model_final_polarity")
        print(f"Final metrics: {metrics}")
    except Exception as e:
        print(f"Training failed: {str(e)}")

if __name__ == "__main__":
    main()

"""# Cell 9: Create the inference file (absa.py)
%%writefile absa.py
import pandas as pd
from setfit import AbsaModel

def absa(reviews):
    '''
    Perform aspect-based sentiment analysis on a list of reviews.
    
    Args:
        reviews (list): List of review strings
        
    Returns:
        pandas.DataFrame: DataFrame with columns review_id, dish, and sentiment
    '''
    # Load the trained model
    model = AbsaModel.from_pretrained(
        "/content/drive/MyDrive/absa_model_latest/aspect",
        "/content/drive/MyDrive/absa_model_latest/polarity",
        spacy_model="en_core_web_sm"
    )
    
    # Predict aspects and sentiments
    predictions = model.predict(reviews)
    
    # Convert predictions to DataFrame format
    rows = []
    for review_id, review_preds in enumerate(predictions):
        for pred in review_preds:
            rows.append({
                'review_id': review_id,
                'dish': pred['span'],
                'sentiment': pred['polarity'].capitalize()
            })
    
    # Create DataFrame
    return pd.DataFrame(rows)

# Cell 10: Test the inference
# Example usage of the absa function
test_reviews = [
    "The pizza was amazing but the pasta was undercooked.",
    "I loved their sushi rolls and the miso soup was perfect."
]

from absa import absa
results = absa(test_reviews)
print(results)
"""